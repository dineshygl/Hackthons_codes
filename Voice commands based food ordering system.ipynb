{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZIubkln0AI2"
   },
   "source": [
    "# Advanced Certification in AIML\n",
    "## A Program by IIIT-H and TalentSprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LNbxek40AI4"
   },
   "source": [
    "# Hackathon : Voice commands based food ordering system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3e0e3sFh0JZJ"
   },
   "source": [
    "### Setup Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWQwfHmR0MDu"
   },
   "outputs": [],
   "source": [
    "#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n",
    "Id = \"P181902276\" #@param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBdFVMDi0Ou0"
   },
   "outputs": [],
   "source": [
    "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
    "password = \"9848253595\" #@param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Kv0xxq_d0Qb_"
   },
   "outputs": [],
   "source": [
    "#@title Run this cell to complete the setup for this Notebook\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "  \n",
    "notebook=\"BLR_M2_Hackathon\" #name of the notebook\n",
    "\n",
    "def setup():\n",
    "#  ipython.magic(\"sx pip3 install torch\")\n",
    "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/Noisy_data.zip\")\n",
    "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/studio_data.zip\")\n",
    "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/Record_audio.py\")\n",
    "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/net_speech_89.pt\")\n",
    "    ipython.magic(\"sx unzip studio_data.zip\")\n",
    "    ipython.magic(\"sx unzip Noisy_data.zip\")\n",
    "    ipython.magic(\"sx pip install torch torchvision\")\n",
    "    ipython.magic(\"sx pip install librosa\")\n",
    "    print (\"Setup completed successfully\")\n",
    "    return\n",
    "\n",
    "def submit_notebook():\n",
    "    \n",
    "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
    "    \n",
    "    import requests, json, base64\n",
    "\n",
    "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
    "    if not submission_id:\n",
    "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
    "      r = requests.post(url, data = data)\n",
    "      r = json.loads(r.text)\n",
    "\n",
    "      if r[\"status\"] == \"Success\":\n",
    "          return r[\"record_id\"]\n",
    "      elif \"err\" in r:        \n",
    "        print(r[\"err\"])\n",
    "        return None        \n",
    "      else:\n",
    "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
    "        return None\n",
    "\n",
    "    elif getComplexity() and getAdditional() and getConcepts():\n",
    "      f = open(notebook + \".ipynb\", \"rb\")\n",
    "      file_hash = base64.b64encode(f.read())\n",
    "\n",
    "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
    "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
    "              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n",
    "\n",
    "      r = requests.post(url, data = data)\n",
    "      print(\"Your submission is successful. Ref:\", submission_id)\n",
    "      return submission_id\n",
    "    else: submission_id\n",
    "    \n",
    "\n",
    "def getAdditional():\n",
    "  try:\n",
    "    if Additional: return Additional      \n",
    "    else: raise NameError('')\n",
    "  except NameError:\n",
    "    print (\"Please answer Additional Question\")\n",
    "    return None\n",
    "\n",
    "def getComplexity():\n",
    "  try:\n",
    "    return Complexity\n",
    "  except NameError:\n",
    "    print (\"Please answer Complexity Question\")\n",
    "    return None\n",
    "  \n",
    "def getConcepts():\n",
    "  try:\n",
    "    return Concepts\n",
    "  except NameError:\n",
    "    print (\"Please answer Concepts Question\")\n",
    "    return None\n",
    "\n",
    "def getId():\n",
    "  try: \n",
    "    return Id if Id else None\n",
    "  except NameError:\n",
    "    return None\n",
    "\n",
    "def getPassword():\n",
    "  try:\n",
    "    return password if password else None\n",
    "  except NameError:\n",
    "    return None\n",
    "\n",
    "submission_id = None\n",
    "### Setup \n",
    "if getPassword() and getId():\n",
    "  submission_id = submit_notebook()\n",
    "  if submission_id:\n",
    "    setup()\n",
    "  \n",
    "else:\n",
    "  print (\"Please complete Id and Password cells before running setup\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqNBNvC25WNV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import warnings\n",
    "from time import sleep\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqMmxLR38vJ3"
   },
   "source": [
    "## Pretrained Network for deep features\n",
    "\n",
    "\n",
    "The following function contains code to load a pre-trained network to produces deep features for the audio sample. This network is trained with delta MFCC features of mono channel 8000 bit rate audio sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDbuxUiL2zYL"
   },
   "outputs": [],
   "source": [
    "def get_network():\n",
    "\n",
    "    net = torch.nn.Sequential()\n",
    "\n",
    "    saved_net = torch.load(\"net_speech_89.pt\").cpu()\n",
    "\n",
    "    for index, module in enumerate(saved_net):\n",
    "        net.add_module(\"layer\"+str(index),module)\n",
    "        if (index+1)%17 == 0 :\n",
    "            break\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "dmoIgxTG5ZnF",
    "outputId": "835c6bfa-0740-4b11-f0c6-da6bed03c52b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (layer0): Linear(in_features=900, out_features=800, bias=True)\n",
       "  (layer1): ReLU()\n",
       "  (layer2): Linear(in_features=800, out_features=700, bias=True)\n",
       "  (layer3): ReLU()\n",
       "  (layer4): Linear(in_features=700, out_features=600, bias=True)\n",
       "  (layer5): ReLU()\n",
       "  (layer6): Linear(in_features=600, out_features=500, bias=True)\n",
       "  (layer7): ReLU()\n",
       "  (layer8): Linear(in_features=500, out_features=400, bias=True)\n",
       "  (layer9): ReLU()\n",
       "  (layer10): Linear(in_features=400, out_features=300, bias=True)\n",
       "  (layer11): ReLU()\n",
       "  (layer12): Linear(in_features=300, out_features=200, bias=True)\n",
       "  (layer13): ReLU()\n",
       "  (layer14): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (layer15): ReLU()\n",
       "  (layer16): Linear(in_features=100, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZS1NA1sATEf"
   },
   "source": [
    "##Obtaining Features from Audio samples\n",
    "Generate features from a audio sample of '.wav' format\n",
    "* Generate Delta MFCC features of order 1 and 2 \n",
    "* Passes them through the above mentioned deep neural net\n",
    "* the obtained deep features are returned\n",
    "\n",
    "Parameters: Filepath (path of audio sample),\n",
    "                       sr (sampling rate, all the samples provided are of 8000 bitrate)\n",
    "         \n",
    "  Caution: Do not change the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTtb2zAj5k0-"
   },
   "outputs": [],
   "source": [
    "def get_features(filepath, sr=8000, n_mfcc=30, n_mels=128, frames = 15):\n",
    "    \n",
    "    \n",
    "    y, sr = librosa.load(filepath, sr=sr)\n",
    "    D = np.abs(librosa.stft(y))**2\n",
    "    S = librosa.feature.melspectrogram(S=D)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    log_S = librosa.power_to_db(S,ref=np.max)\n",
    "    features = librosa.feature.mfcc(S=log_S, n_mfcc=n_mfcc)\n",
    "    if features.shape[1] < frames :\n",
    "        features = np.hstack((features, np.zeros((n_mfcc, frames - features.shape[1]))))\n",
    "    elif features.shape[1] > frames:\n",
    "        features = features[:, :frames]\n",
    "    # Find 1st order delta_mfcc\n",
    "    delta1_mfcc = librosa.feature.delta(features, order=1)\n",
    "\n",
    "    # Find 2nd order delta_mfcc\n",
    "    delta2_mfcc = librosa.feature.delta(features, order=2)\n",
    "    features = np.hstack((delta1_mfcc.flatten(), delta2_mfcc.flatten()))\n",
    "    features = features.flatten()[np.newaxis, :]\n",
    "    features = Variable(torch.from_numpy(features)).float()\n",
    "    deep_net = get_network()\n",
    "    deep_features = deep_net(features)\n",
    "    #print(features.shape)\n",
    "    #print(audio_file)\n",
    "    #features.flatten()[np.newaxis, :]\n",
    "    return deep_features.data.numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NhLFY4n6BwIj"
   },
   "source": [
    "## All the voice sample needed for training are present across the folders \"Noisy_data\" and \"studio_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "B4-clpEl-1RF",
    "outputId": "13e18a4f-0f07-465c-e89b-ac2e0cb63c85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLR_M2_Hackathon.ipynb  \u001b[0m\u001b[01;34mNoisy_data\u001b[0m/      \u001b[01;34msample_data\u001b[0m/\n",
      "\u001b[01;34m__MACOSX\u001b[0m/               Noisy_data.zip   \u001b[01;34mstudio_data\u001b[0m/\n",
      "net_speech_89.pt        Record_audio.py  studio_data.zip\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SB-LowDuCMUL"
   },
   "source": [
    "##Stage 1: \n",
    "#### Max. Marks: 5\n",
    "#### Complete the code in the load_data function\n",
    "\n",
    "* The function should take path of the folder containing audio samples as input\n",
    "* It should return features of all the audio samples present in the specified folder into single array (list of lists or 2-d numpy array) and their respective labels should be returned too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qDzCa-532EUj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_data(path):\n",
    "    files = []\n",
    "    feat=[]\n",
    "    label=[]\n",
    "    for r,d,f in os.walk(path):\n",
    "        for file in f:\n",
    "            if '.wav' in file:\n",
    "                files.append(os.path.join(r,file))\n",
    "    for f in files:\n",
    "        feat.append(get_features(f))\n",
    "        label.append(re.search(r'\\d+',f).group(0))\n",
    "   \n",
    "    features=np.asarray(feat)\n",
    "    labels=np.asarray(label)\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8_pH4uQh65T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([], dtype=float64))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data('studio_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRXCxXjVnxA8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7673ezpxFEfM"
   },
   "source": [
    "####load data and labels from studio_data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5CjrlPVPjNs"
   },
   "outputs": [],
   "source": [
    "studio_recorded_features, studio_recorded_labels = load_data('/content/studio_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iwI-JzCVprCo",
    "outputId": "4a9d89de-b2bc-46b7-87d7-1eae0f34d9ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,) (0,)\n"
     ]
    }
   ],
   "source": [
    "print(studio_recorded_features.shape,studio_recorded_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G8elKkTsvhy6",
    "outputId": "378a1d60-cd5f-4b1d-d49a-fdc0939e8674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(studio_recorded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGq6XpvhFynP"
   },
   "source": [
    "##Stage 2:\n",
    "\n",
    "####Max. Marks:18\n",
    "\n",
    "#### Train a classifier on the features obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "VU5hdERsFw5o",
    "outputId": "8b800e32-e00c-4efc-cc4a-1807aa2a7e06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of K:  1\n",
      "Accuracy:  0.8766310794780545\n",
      "Values of K:  3\n",
      "Accuracy:  0.863582443653618\n",
      "Values of K:  5\n",
      "Accuracy:  0.8754448398576512\n",
      "Values of K:  7\n",
      "Accuracy:  0.9098457888493475\n",
      "Values of K:  9\n",
      "Accuracy:  0.8612099644128114\n",
      "Values of K:  11\n",
      "Accuracy:  0.8884934756820878\n",
      "Values of K:  13\n",
      "Accuracy:  0.8979833926453143\n",
      "Values of K:  15\n",
      "Accuracy:  0.8861209964412812\n",
      "Values of K:  17\n",
      "Accuracy:  0.8718861209964412\n",
      "Values of K:  19\n",
      "Accuracy:  0.8956109134045077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "values_of_k = [1,3,5,7,9,11,13,15,17,19]\n",
    "\n",
    "for i in range(len(values_of_k)):\n",
    "    knc = KNeighborsClassifier(values_of_k[i])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(studio_recorded_features,studio_recorded_labels,test_size=0.1)\n",
    "    knc.fit(X_train,y_train)\n",
    "    # print(X_train.shape,y_train.shape)\n",
    "    predict =knc.predict(X_test)\n",
    "    acuracy = accuracy_score(y_test,predict)\n",
    "    print('Values of K: ',values_of_k[i])\n",
    "    acuracy\n",
    "    print('Accuracy: ',acuracy)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "y7CKO0S0oOBA",
    "outputId": "93b25df2-8f11-4f84-9447-74cbdf416865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method KNeighborsClassifier.predict_proba of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=19, p=2,\n",
      "                     weights='uniform')>\n"
     ]
    }
   ],
   "source": [
    "print(knc.predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGixO_z6Gf-Y"
   },
   "source": [
    "####Save your model\n",
    "\n",
    "Hint:\n",
    "* Incase if you are using scikit learn model for training, you can use joblib package to save the model.\n",
    "* Manually implemented models as a function or class can be saved using pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mubiwIuTQIev"
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ut8aQN5_G7bx"
   },
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib\n",
    "filename = 'finalized_model_std.sav'\n",
    "joblib.dump(knc, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eJb_Dr67QKH3",
    "outputId": "8e6d8465-ff31-432d-9a43-cd4a706fa320"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalized_model_std.sav']"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(knc, 'finalized_model_std.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L3RpW61NPlUq",
    "outputId": "5db84637-f31c-4d48-fef0-361297a94e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joblib==0.12.5\n"
     ]
    }
   ],
   "source": [
    "  !pip freeze | grep joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsCHKXubHAJB"
   },
   "source": [
    "#### Download your trained model using the code below\n",
    "* given the path of model file the following code downloads it through the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDmWXfPaHJZG"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('finalized_model_std.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyzwUhYP03OM"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7ccsM_ZISWj"
   },
   "source": [
    "\n",
    "##Stage 3: (Application Deployment)\n",
    "\n",
    "#### Max. Marks: 5M\n",
    "#### Now deploy the model trained on studio_data in the sever to order food correctly. \n",
    "#### Deployment instruction are given the Hackathon documentation\n",
    "#### After deploying and checking the application come back here to train on Noisy_data to generalise better in real situations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VFOudw7XGDeQ"
   },
   "source": [
    "#### load data and labels from Noisy_data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LLejdkbCat2"
   },
   "outputs": [],
   "source": [
    "noisy_data, noisy_data_labels = load_data('/content/Noisy_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5Kd5JKYPIGEL",
    "outputId": "bfe73196-3ef8-49c7-81e3-c297780ec2ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8423, 50) (11839, 50)\n",
      "(20262, 50)\n"
     ]
    }
   ],
   "source": [
    "print(studio_recorded_features.shape,noisy_data.shape)\n",
    "merg_feature = np.concatenate((studio_recorded_features, noisy_data))\n",
    "print(merg_feature.shape)\n",
    "# studio_recorded_features, studio_recorded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8bkIP2dJsrZ"
   },
   "outputs": [],
   "source": [
    "merg_labels = np.concatenate((studio_recorded_labels, noisy_data_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EE7wMbMDJKkC",
    "outputId": "07c132ff-e1f0-4180-f897-e923d1401e1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20262,)"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merg_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "07_FP1noJPGj",
    "outputId": "fef65bc4-f17a-445a-df73-f5371a43f623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8423,)"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studio_recorded_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wPmAbksHGK0a"
   },
   "source": [
    "## Stage 4:\n",
    "####Max. Marks:8\n",
    "#### Train a classifier on the features obtained from both the Noisy_data and Studio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "XyZ16AUKGeoN",
    "outputId": "8df7f14e-fbd5-429e-e095-8a93fa446969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of k:  1\n",
      "Accuracy:  0.4814997533300444\n",
      "Value of k:  3\n",
      "Accuracy:  0.5051800690675876\n",
      "Value of k:  5\n",
      "Accuracy:  0.5515540207202763\n",
      "Value of k:  7\n",
      "Accuracy:  0.5624074987666502\n",
      "Value of k:  9\n",
      "Accuracy:  0.5609274790330537\n",
      "Value of k:  11\n",
      "Accuracy:  0.5693142575234337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "values_of_k = [1,3,5,7,9,11]\n",
    "\n",
    "for i in range(len(values_of_k)):\n",
    "    mknc = KNeighborsClassifier(values_of_k[i])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(merg_feature,merg_labels,test_size=0.1)\n",
    "    mknc.fit(X_train,y_train)\n",
    "    # print(X_train.shape,y_train.shape)\n",
    "    mpredict =mknc.predict(X_test)\n",
    "    macuracy = accuracy_score(y_test,mpredict)\n",
    "    print('Value of k: ',values_of_k[i])\n",
    "    print('Accuracy: ',macuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJlS0qjmIEYz"
   },
   "source": [
    "#### Download your trained model using the code below\n",
    "* given the path of model file the following code downloads it through the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUM_6cP-IJy5"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('<model_file_path>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzhCSHRpVfdV"
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "55h5MNexVmIc",
    "outputId": "cf1f1aab-c9f3-45c1-a49e-0dff6cb55597"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['merged_model_std.sav']"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(mknc, 'merged_model_std.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jA829HXjIe5Z"
   },
   "source": [
    "#### Now deploy the model trained above in the sever to order food correctly. \n",
    "#### Deployment instruction are given the Hackathon documentation\n",
    "#### After deploying and checking the application, record your teams data from the web application provided in the Hackathon document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv3I24flWlLq"
   },
   "outputs": [],
   "source": [
    "!mkdir teamdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TWrJSY-OGyG9"
   },
   "source": [
    "Replace <YOUR_GROUP_ID> with your group id given in the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gB_bSllKWJ5U"
   },
   "outputs": [],
   "source": [
    "!wget -r -A .wav https://aiml-sandbox1.talentsprint.com/audio_recorder/b9h1g16/team_data/ -nH --cut-dirs=100  -P ./team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "kXYUWdd2WZlA",
    "outputId": "fe8b3cc1-218b-4899-e2b5-2f874b2846ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLR_M2_Hackathon.ipynb   net_speech_89.pt  \u001b[0m\u001b[01;34msample_data\u001b[0m/     \u001b[01;34mteam_data\u001b[0m/\n",
      "finalized_model_std.pkl  \u001b[01;34mNoisy_data\u001b[0m/       \u001b[01;34mstudio_data\u001b[0m/\n",
      "finalized_model_std.sav  Noisy_data.zip    studio_data.zip\n",
      "\u001b[01;34m__MACOSX\u001b[0m/                Record_audio.py   \u001b[01;34mteamdata\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zU556OeCL0x9"
   },
   "outputs": [],
   "source": [
    "!unzip <zip_file_name>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wH17k1RciuM_"
   },
   "source": [
    "##Stage 5:\n",
    "#### Max. Marks: 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6Wg6uG0L_qz"
   },
   "source": [
    "## Enhance the model trained with both the noisy data and studio_data to your team's voice samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwKko3-yL-0a"
   },
   "outputs": [],
   "source": [
    "team_recorded_features, team_recorded_labels = load_data('/content/team_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EowkpCDpalXL",
    "outputId": "c85b924b-e9ea-4555-e6e1-6ad454e2ed40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 50)\n"
     ]
    }
   ],
   "source": [
    "print(team_recorded_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eNkJ0P48Z7og",
    "outputId": "3652b386-a1e2-4c82-da2a-c4d12705c963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20322, 50)\n"
     ]
    }
   ],
   "source": [
    "team_features = np.concatenate((team_recorded_features, merg_feature))\n",
    "print(team_features.shape)\n",
    "# team_labels = np.concatenate(team_recorded_labels,merg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "42rLy64jeccA",
    "outputId": "37a30080-8e51-47f4-a667-e541aeab148d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20322,)\n"
     ]
    }
   ],
   "source": [
    "team_labels = np.concatenate((team_recorded_labels,merg_labels))\n",
    "print(team_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "3em7VBnFetSJ",
    "outputId": "3c03e4ba-6793-4ce0-ff67-d2ded36ba89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of K:  1\n",
      "Accuracy:  0.485489424495819\n",
      "Value of K:  3\n",
      "Accuracy:  0.5218888342351206\n",
      "Value of K:  5\n",
      "Accuracy:  0.52926709296606\n",
      "Value of K:  7\n",
      "Accuracy:  0.5568125922282341\n",
      "Value of K:  9\n",
      "Accuracy:  0.5646827348745695\n",
      "Value of K:  11\n",
      "Accuracy:  0.5558288243974422\n",
      "Value of K:  13\n",
      "Accuracy:  0.5602557796360059\n",
      "Value of K:  15\n",
      "Accuracy:  0.5553369404820462\n",
      "Value of K:  17\n",
      "Accuracy:  0.5479586817511067\n",
      "Value of K:  19\n",
      "Accuracy:  0.5538612887358584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "values_of_k = [1,3,5,7,9,11,13,15,17,19]\n",
    "\n",
    "for i in range(len(values_of_k)):\n",
    "    tknc = KNeighborsClassifier(values_of_k[i])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(team_features,team_labels,test_size=0.1)\n",
    "    tknc.fit(X_train,y_train)\n",
    "    # print(X_train.shape,y_train.shape)\n",
    "    tpredict =tknc.predict(X_test)\n",
    "    tacuracy = accuracy_score(y_test,tpredict)\n",
    "    tacuracy\n",
    "    print('Value of K: ',values_of_k[i])\n",
    "    print('Accuracy: ',tacuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oUUO_lrgfL_z",
    "outputId": "07f89f7c-18e1-428b-bcab-8217495b359e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team_model_std.sav']"
      ]
     },
     "execution_count": 156,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(tknc, 'team_model_std.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQhiuXMaMRp2"
   },
   "source": [
    "### Now deploy the model trained above in the sever to order food correctly. \n",
    "### Deployment instruction are given the Hackathon documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jx6Y0Roy19a0"
   },
   "source": [
    "### Please answer the questions below to complete the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-O68_f5E2Az_"
   },
   "outputs": [],
   "source": [
    "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
    "Complexity = \"Good and Challenging me\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YpxQ61Q2CjX"
   },
   "outputs": [],
   "source": [
    "#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
    "Additional = \"NA\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZWB9A6M2Fuv"
   },
   "outputs": [],
   "source": [
    "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
    "Concepts = \"Yes\" #@param [\"Yes\", \"No\"]4819687275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "03H962QV2Haz"
   },
   "outputs": [],
   "source": [
    "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
    "try:\n",
    "  if submission_id:\n",
    "      return_id = submit_notebook()\n",
    "      if return_id : submission_id =return_id\n",
    "  else:\n",
    "      print(\"Please complete the setup first.\")\n",
    "except NameError:\n",
    "  print (\"Please complete the setup first.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hackathon_I_Starter_Code.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
